# ü©∫ Analyse et Pr√©diction du Risque de Diab√®te

## üìã Pr√©sentation

Ce projet vise √† analyser un jeu de donn√©es sur le diab√®te afin d'identifier des groupes de patients √† risque via des techniques de clustering (apprentissage non supervis√©). Ensuite, plusieurs mod√®les de classification (apprentissage supervis√©) sont entra√Æn√©s pour pr√©dire l'appartenance d'un patient √† un groupe de risque, permettant ainsi une identification pr√©coce et une meilleure prise en charge.

**Objectif m√©tier :** Segmenter les patients en cat√©gories de "risque √©lev√©" et "risque faible" en se basant sur leurs donn√©es m√©dicales, puis construire un mod√®le pr√©dictif fiable pour automatiser cette classification. Les variables utilis√©es incluent :
*   Nombre de grossesses (Pregnancies)
*   Concentration en glucose (Glucose)
*   Pression art√©rielle (BloodPressure)
*   √âpaisseur du pli cutan√© (SkinThickness)
*   Niveau d'insuline (Insulin)
*   Indice de masse corporelle (BMI)
*   Fonction g√©n√©alogique du diab√®te (DiabetesPedigreeFunction)
*   √Çge (Age)

## üßë‚Äçüî¨ Pipeline & Fonctionnalit√©s

1.  **Analyse Exploratoire des Donn√©es (EDA)**
    *   Importation et exploration initiale du jeu de donn√©es.
    *   Visualisation des distributions, des relations et des corr√©lations.
    *   Identification des z√©ros comme valeurs manquantes implicites dans plusieurs colonnes critiques (`Glucose`, `Insulin`, etc.).

2.  **Pr√©traitement des Donn√©es**
    *   **Gestion des valeurs manquantes :** Remplacement des z√©ros par `NaN`, puis imputation √† l'aide de l'algorithme `KNNImputer` pour une estimation plus pr√©cise.
    *   **D√©tection et traitement des valeurs aberrantes (outliers) :** Visualisation avec `boxplot` et application d'une m√©thode de plafonnement (capping) bas√©e sur l'√©cart interquartile (IQR) pour limiter leur influence.
    *   **Standardisation :** Mise √† l'√©chelle des variables num√©riques avec `StandardScaler` pour que les mod√®les ne soient pas biais√©s par les diff√©rentes √©chelles de valeurs.

3.  **Segmentation Non Supervis√©e (Clustering)**
    *   **Choix de l'algorithme :** Utilisation de `K-Means` pour partitionner les donn√©es.
    *   **D√©termination du nombre de clusters :** Application des m√©thodes du coude (Elbow Method) et de la silhouette pour identifier le nombre optimal de groupes (k=2).
    *   **Visualisation et Interpr√©tation :** R√©duction de la dimensionnalit√© avec `PCA` pour visualiser les clusters et analyse des centro√Ødes pour caract√©riser les profils de chaque groupe ("risque √©lev√©" vs "risque faible").

4.  **Entra√Ænement des Mod√®les de Classification**
    *   **Pr√©paration :** Division des donn√©es en ensembles d'entra√Ænement et de test.
    *   **Gestion du d√©s√©quilibre des classes :** Utilisation de `RandomOverSampler` pour s'assurer que les mod√®les sont entra√Æn√©s sur un nombre √©quilibr√© d'exemples de chaque classe.
    *   **Impl√©mentation de plusieurs mod√®les :**
        *   `LogisticRegression`
        *   `DecisionTreeClassifier`
        *   `RandomForestClassifier`
        *   `SVC` (Support Vector Classifier)
        *   `GradientBoostingClassifier`
        *   `XGBClassifier`

5.  **√âvaluation et Comparaison**
    *   **M√©triques :** √âvaluation de chaque mod√®le √† l'aide de la pr√©cision, du rappel (recall), du F1-score et de la matrice de confusion.
    *   **Synth√®se :** Cr√©ation d'un tableau r√©capitulatif pour comparer les performances des mod√®les. La **R√©gression Logistique** et le **SVM** se sont r√©v√©l√©s √™tre les plus performants.

6.  **Test, Export et D√©ploiement**
    *   **Export du mod√®le** finalis√© (via `joblib`).
    *   **Interface utilisateur simple** pour tester une pr√©diction √† partir de donn√©es saisies.

7.  **Documentation et Reproductibilit√©**
    *   **Code comment√©** et √©tapes d√©taill√©es dans le notebook.
    *   **Instructions claires d‚Äôex√©cution** dans ce README.

## üöÄ Comment ex√©cuter le projet

1.  **Cloner le d√©p√¥t**
    ```bash
    git clone https://github.com/elmhmmd/Pr-dicteur-de-Charges-d-Assurance-Maladie
    cd Pr-dicteur-de-Charges-d-Assurance-Maladie
    ```

2.  **Installer les d√©pendances**
    Assurez-vous d'avoir Python install√©. Ensuite, installez les biblioth√®ques n√©cessaires :
    ```bash
    pip install numpy pandas seaborn scikit-learn xgboost matplotlib imbalanced-learn
    ```

3.  **Lancer le notebook Jupyter**
    Le code est structur√© dans un notebook Jupyter. Lancez-le pour suivre toutes les √©tapes de l'analyse, du pr√©traitement et de l'entra√Ænement des mod√®les.
    ```bash
    jupyter notebook Diabetes.ipynb
    ```

4.  **Lancer l'interface Streamlit**
    Pour une d√©monstration interactive, lancez l'application Streamlit.
    ```bash
    streamlit run Interface.py
    ```
